# äººè„¸è¡¨æƒ…è¯†åˆ«
# ç¯å¢ƒ: Python + PyTorch + GPU
# åŠŸèƒ½: ä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰è®­ç»ƒä¸€ä¸ªè¡¨æƒ…åˆ†ç±»å™¨
import os
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models # type: ignore
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
# ----------------------------------------------------------
# 1ï¸âƒ£ è®¾ç½®æ•°æ®é›†è·¯å¾„ï¼ˆæ”¹æˆä½ è‡ªå·±çš„è·¯å¾„ï¼‰
# ----------------------------------------------------------
train_dir = r"C:\Users\rog1\Desktop\äººè„¸è¡¨æƒ…è¯†åˆ«æ•°æ®é›†\archive\train"
test_dir = r"C:\Users\rog1\Desktop\äººè„¸è¡¨æƒ…è¯†åˆ«æ•°æ®é›†\archive\test"

# ----------------------------------------------------------
# 2ï¸âƒ£ å®šä¹‰å›¾åƒé¢„å¤„ç†æ–¹å¼ï¼ˆtransformsï¼‰
# transforms.Resize((48,48)) è¡¨ç¤ºæŠŠæ‰€æœ‰å›¾ç‰‡ç¼©æ”¾åˆ° 48x48 åƒç´ 
# transforms.ToTensor() æŠŠå›¾ç‰‡è½¬ä¸º PyTorch å¼ é‡
# transforms.Normalize() è®©æ¨¡å‹æ›´ç¨³å®š
# ----------------------------------------------------------
transform = transforms.Compose([
    transforms.Resize((48, 48)),
    transforms.RandomHorizontalFlip(),   # ä¿ç•™
    transforms.RandomRotation(10),       # æ”¹æˆ Â±10Â°
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])
# ----------------------------------------------------------
# 3ï¸âƒ£ ä½¿ç”¨ ImageFolder è‡ªåŠ¨åŠ è½½æ•°æ®
# å®ƒä¼šæ ¹æ®å­æ–‡ä»¶å¤¹åå­—è‡ªåŠ¨ç”Ÿæˆæ ‡ç­¾
# ----------------------------------------------------------
train_dataset = datasets.ImageFolder(train_dir,transform=transform)
test_dataset = datasets.ImageFolder(test_dir,transform=transform)

# ----------------------------------------------------------
# 4ï¸âƒ£ åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆDataLoaderï¼‰
# batch_size = 64 è¡¨ç¤ºæ¯æ¬¡è®­ç»ƒè¯»å– 64 å¼ å›¾ç‰‡
# shuffle=True è¡¨ç¤ºæ‰“ä¹±è®­ç»ƒæ•°æ®é¡ºåº
train_loader = DataLoader(train_dataset,batch_size = 64,shuffle = True)
test_loader = DataLoader(test_dataset,batch_size = 64,shuffle = False)

print("ç±»åˆ«åˆ—è¡¨",train_dataset.classes)
print("è®­ç»ƒæ ·æœ¬æ•°é‡",len(train_dataset))
print("æµ‹è¯•æ ·æœ¬æ•°é‡",len(test_dataset))

# ----------------------------------------------------------
# 5ï¸âƒ£ æ£€æŸ¥æ˜¯å¦å¯ä»¥ä½¿ç”¨ GPUï¼ˆCUDAï¼‰
# ----------------------------------------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("ä½¿ç”¨è®¾å¤‡:",{device})


#å®šä¹‰ä¸€ä¸ªæ®‹å·®å—æ¥æå‡å‡†ç¡®ç‡
class ResidualBlock(nn.Module):
    def __init__(self, channels):
        super(ResidualBlock, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(channels, channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(channels),
            nn.ReLU(),
            nn.Conv2d(channels, channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(channels)
        )
        self.relu = nn.ReLU()

    def forward(self, x):
        out = self.conv(x)
        out += x  # æ®‹å·®è¿æ¥ï¼šè¾“å‡º + è¾“å…¥
        return self.relu(out)


# ----------------------------------------------------------
# 6ï¸âƒ£ å®šä¹‰ä¸€ä¸ªåŠ äº†æ®‹å·®å—çš„çš„ CNN æ¨¡å‹
# ----------------------------------------------------------
class DeepResCNN(nn.Module):
    def __init__(self, num_classes):
        super(DeepResCNN, self).__init__()

        self.features = nn.Sequential(
            # Block 1
            nn.Conv2d(3, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),  # 48x48 -> 24x24

            # Block 2 + æ®‹å·®å—
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            ResidualBlock(64),
            nn.MaxPool2d(2, 2),  # 24x24 -> 12x12

            # Block 3 + æ®‹å·®å—
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            ResidualBlock(128),
            nn.MaxPool2d(2, 2),  # 12x12 -> 6x6
        )

        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(128 * 6 * 6, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, num_classes)
        )

    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x
# ----------------------------------------------------------
# 7ï¸âƒ£ å®ä¾‹åŒ–æ¨¡å‹
# len(train_dataset.classes) ä¼šè‡ªåŠ¨è·å–ç±»åˆ«æ•°é‡
# ----------------------------------------------------------
model = DeepResCNN(num_classes=len(train_dataset.classes)).to(device)

# ----------------------------------------------------------
# 8ï¸âƒ£ å®šä¹‰æŸå¤±å‡½æ•°ä¸ä¼˜åŒ–å™¨
# CrossEntropyLossï¼šå¤šåˆ†ç±»å¸¸ç”¨çš„æŸå¤±å‡½æ•°
# Adamï¼šä¸€ç§å¸¸ç”¨çš„ä¼˜åŒ–ç®—æ³•
# ----------------------------------------------------------
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr = 0.0002)

# ----------------------------------------------------------
# 9ï¸âƒ£ å¼€å§‹è®­ç»ƒå¾ªç¯
# ----------------------------------------------------------
num_epochs = 25
train_losses = []  # è®°å½•æ¯è½®è®­ç»ƒçš„å¹³å‡æŸå¤±
train_accuracies = []  # è®°å½•æ¯è½®è®­ç»ƒçš„å‡†ç¡®ç‡

for epoch in range(num_epochs):
    model.train()
    running_loss = 0
    correct = 0
    total = 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()  # æ¸…ç©ºæ¢¯åº¦
        outputs = model(images)  # å‰å‘ä¼ æ’­
        loss = criterion(outputs, labels)  # è®¡ç®—æŸå¤±
        loss.backward()  # åå‘ä¼ æ’­
        optimizer.step()  # æ›´æ–°å‚æ•°

        running_loss += loss.item()
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    avg_loss = running_loss / len(train_loader)
    train_acc = 100 * correct / total
    train_losses.append(avg_loss)
    train_accuracies.append(train_acc)

    print(f"Epoch [{epoch+1}/{num_epochs}] | Loss: {avg_loss:.4f} | Train Acc: {train_acc:.2f}%")

# ----------------------------------------------------------
# ğŸ”Ÿ ç»˜åˆ¶è®­ç»ƒè¿‡ç¨‹æ›²çº¿
# ----------------------------------------------------------
plt.figure(figsize=(10,4))

# å­å›¾1: æŸå¤±æ›²çº¿
plt.subplot(1,2,1)
plt.plot(train_losses, label="Training Loss", color='red')
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Training Loss Curve")
plt.legend()

# å­å›¾2: å‡†ç¡®ç‡æ›²çº¿
plt.subplot(1,2,2)
plt.plot(train_accuracies, label="Training Accuracy", color='blue')
plt.xlabel("Epoch")
plt.ylabel("Accuracy (%)")
plt.title("Training Accuracy Curve")
plt.legend()

plt.tight_layout()
plt.show()
